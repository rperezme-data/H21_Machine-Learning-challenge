{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: sklearn in c:\\users\\rpmcl\\anaconda3\\envs\\pythondata\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn in c:\\users\\rpmcl\\anaconda3\\envs\\pythondata\\lib\\site-packages (from sklearn) (0.24.1)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in c:\\users\\rpmcl\\anaconda3\\envs\\pythondata\\lib\\site-packages (from scikit-learn->sklearn) (1.5.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in c:\\users\\rpmcl\\anaconda3\\envs\\pythondata\\lib\\site-packages (from scikit-learn->sklearn) (1.18.5)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in c:\\users\\rpmcl\\anaconda3\\envs\\pythondata\\lib\\site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in c:\\users\\rpmcl\\anaconda3\\envs\\pythondata\\lib\\site-packages (from scikit-learn->sklearn) (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "## Update sklearn to prevent version mismatches:\n",
    "!pip install sklearn --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in c:\\users\\rpmcl\\anaconda3\\envs\\pythondata\\lib\\site-packages (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "## Install joblib (to save model): \n",
    "## *Restart your kernel after installing \n",
    "!pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dependencies\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read CSV & Perform Basic Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_time0bk_err2</th>\n",
       "      <th>koi_impact</th>\n",
       "      <th>koi_impact_err1</th>\n",
       "      <th>koi_impact_err2</th>\n",
       "      <th>koi_duration</th>\n",
       "      <th>koi_duration_err1</th>\n",
       "      <th>koi_duration_err2</th>\n",
       "      <th>koi_depth</th>\n",
       "      <th>koi_depth_err1</th>\n",
       "      <th>koi_depth_err2</th>\n",
       "      <th>koi_prad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.003520</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.059</td>\n",
       "      <td>-0.443</td>\n",
       "      <td>4.50700</td>\n",
       "      <td>0.11600</td>\n",
       "      <td>-0.11600</td>\n",
       "      <td>874.8</td>\n",
       "      <td>35.5</td>\n",
       "      <td>-35.5</td>\n",
       "      <td>2.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.000581</td>\n",
       "      <td>0.969</td>\n",
       "      <td>5.126</td>\n",
       "      <td>-0.077</td>\n",
       "      <td>1.78220</td>\n",
       "      <td>0.03410</td>\n",
       "      <td>-0.03410</td>\n",
       "      <td>10829.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>14.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.000115</td>\n",
       "      <td>1.276</td>\n",
       "      <td>0.115</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>2.40641</td>\n",
       "      <td>0.00537</td>\n",
       "      <td>-0.00537</td>\n",
       "      <td>8079.2</td>\n",
       "      <td>12.8</td>\n",
       "      <td>-12.8</td>\n",
       "      <td>33.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.001130</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.235</td>\n",
       "      <td>-0.478</td>\n",
       "      <td>1.65450</td>\n",
       "      <td>0.04200</td>\n",
       "      <td>-0.04200</td>\n",
       "      <td>603.3</td>\n",
       "      <td>16.9</td>\n",
       "      <td>-16.9</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.001900</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.139</td>\n",
       "      <td>-0.532</td>\n",
       "      <td>3.14020</td>\n",
       "      <td>0.06730</td>\n",
       "      <td>-0.06730</td>\n",
       "      <td>686.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>-18.7</td>\n",
       "      <td>2.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.004610</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.212</td>\n",
       "      <td>-0.523</td>\n",
       "      <td>2.42900</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>-0.16500</td>\n",
       "      <td>226.5</td>\n",
       "      <td>16.8</td>\n",
       "      <td>-16.8</td>\n",
       "      <td>1.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.000517</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.262</td>\n",
       "      <td>-0.052</td>\n",
       "      <td>3.53470</td>\n",
       "      <td>0.02410</td>\n",
       "      <td>-0.02410</td>\n",
       "      <td>4914.3</td>\n",
       "      <td>33.3</td>\n",
       "      <td>-33.3</td>\n",
       "      <td>5.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.000009</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>1.74319</td>\n",
       "      <td>0.00107</td>\n",
       "      <td>-0.00107</td>\n",
       "      <td>14231.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>-4.2</td>\n",
       "      <td>13.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.000016</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.159</td>\n",
       "      <td>-0.216</td>\n",
       "      <td>3.88864</td>\n",
       "      <td>0.00203</td>\n",
       "      <td>-0.00203</td>\n",
       "      <td>6674.7</td>\n",
       "      <td>1.7</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>16.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.000047</td>\n",
       "      <td>0.631</td>\n",
       "      <td>0.007</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>3.19843</td>\n",
       "      <td>0.00653</td>\n",
       "      <td>-0.00653</td>\n",
       "      <td>9145.7</td>\n",
       "      <td>6.6</td>\n",
       "      <td>-6.6</td>\n",
       "      <td>14.59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   koi_time0bk_err2  koi_impact  koi_impact_err1  koi_impact_err2  \\\n",
       "0         -0.003520       0.586            0.059           -0.443   \n",
       "1         -0.000581       0.969            5.126           -0.077   \n",
       "2         -0.000115       1.276            0.115           -0.092   \n",
       "3         -0.001130       0.701            0.235           -0.478   \n",
       "4         -0.001900       0.762            0.139           -0.532   \n",
       "5         -0.004610       0.755            0.212           -0.523   \n",
       "6         -0.000517       0.052            0.262           -0.052   \n",
       "7         -0.000009       0.818            0.001           -0.001   \n",
       "8         -0.000016       0.224            0.159           -0.216   \n",
       "9         -0.000047       0.631            0.007           -0.007   \n",
       "\n",
       "   koi_duration  koi_duration_err1  koi_duration_err2  koi_depth  \\\n",
       "0       4.50700            0.11600           -0.11600      874.8   \n",
       "1       1.78220            0.03410           -0.03410    10829.0   \n",
       "2       2.40641            0.00537           -0.00537     8079.2   \n",
       "3       1.65450            0.04200           -0.04200      603.3   \n",
       "4       3.14020            0.06730           -0.06730      686.0   \n",
       "5       2.42900            0.16500           -0.16500      226.5   \n",
       "6       3.53470            0.02410           -0.02410     4914.3   \n",
       "7       1.74319            0.00107           -0.00107    14231.0   \n",
       "8       3.88864            0.00203           -0.00203     6674.7   \n",
       "9       3.19843            0.00653           -0.00653     9145.7   \n",
       "\n",
       "   koi_depth_err1  koi_depth_err2  koi_prad  \n",
       "0            35.5           -35.5      2.83  \n",
       "1           171.0          -171.0     14.60  \n",
       "2            12.8           -12.8     33.46  \n",
       "3            16.9           -16.9      2.75  \n",
       "4            18.7           -18.7      2.77  \n",
       "5            16.8           -16.8      1.59  \n",
       "6            33.3           -33.3      5.76  \n",
       "7             4.2            -4.2     13.04  \n",
       "8             1.7            -1.7     16.10  \n",
       "9             6.6            -6.6     14.59  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../Resources/Data/exoplanet_data.csv\")\n",
    "# Drop the null columns where all values are null\n",
    "df = df.dropna(axis='columns', how='all')\n",
    "# Drop the null rows\n",
    "df = df.dropna()\n",
    "df.iloc[:,10:21].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6991, 41)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Target & Select Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FALSE POSITIVE    3504\n",
       "CONFIRMED         1800\n",
       "CANDIDATE         1687\n",
       "Name: koi_disposition, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = df['koi_disposition']\n",
    "target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = df.drop(columns=['koi_disposition']).columns\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['koi_fpflag_nt', 'koi_fpflag_ss', 'koi_fpflag_co', 'koi_fpflag_ec',\n",
       "       'koi_period', 'koi_period_err1', 'koi_period_err2', 'koi_time0bk',\n",
       "       'koi_time0bk_err1', 'koi_time0bk_err2', 'koi_impact', 'koi_impact_err1',\n",
       "       'koi_impact_err2', 'koi_duration', 'koi_duration_err1',\n",
       "       'koi_duration_err2', 'koi_depth', 'koi_depth_err1', 'koi_depth_err2',\n",
       "       'koi_prad', 'koi_prad_err1', 'koi_prad_err2', 'koi_teq', 'koi_insol',\n",
       "       'koi_insol_err1', 'koi_insol_err2', 'koi_model_snr', 'koi_tce_plnt_num',\n",
       "       'koi_steff', 'koi_steff_err1', 'koi_steff_err2', 'koi_slogg',\n",
       "       'koi_slogg_err1', 'koi_slogg_err2', 'koi_srad', 'koi_srad_err1',\n",
       "       'koi_srad_err2', 'ra', 'dec', 'koi_kepmag'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features (remove error columns)\n",
    "selected_features = df[\n",
    "    'koi_fpflag_nt', 'koi_fpflag_ss', 'koi_fpflag_co', 'koi_fpflag_ec',\n",
    "    'koi_period', 'koi_time0bk', 'koi_impact', 'koi_duration',\n",
    "    'koi_depth', 'koi_prad', 'koi_teq', 'koi_insol',\n",
    "    'koi_model_snr', 'koi_tce_plnt_num', 'koi_steff', 'koi_slogg',\n",
    "    'koi_srad', 'ra', 'dec', 'koi_kepmag'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train / Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(selected_features, target, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "0.25\n"
     ]
    }
   ],
   "source": [
    "## Check split\n",
    "print(round(len(X_train)/len(selected_features), 2))\n",
    "print(round(len(X_test)/len(selected_features), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "0.25\n"
     ]
    }
   ],
   "source": [
    "print(round(len(y_train)/len(target), 2))\n",
    "print(round(len(y_test)/len(target), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rpmcl\\anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\rpmcl\\anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\rpmcl\\anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\rpmcl\\anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\rpmcl\\anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\rpmcl\\anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\rpmcl\\anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\rpmcl\\anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\rpmcl\\anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\rpmcl\\anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\rpmcl\\anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\rpmcl\\anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "## Encode Target\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "## Label-encode\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(target)\n",
    "y_train_encoded = label_encoder.transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "## One-hot encoding\n",
    "y_train_categorical = to_categorical(y_train_encoded)\n",
    "y_test_categorical = to_categorical(y_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CANDIDATE', 'CONFIRMED', 'FALSE POSITIVE'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_names = label_encoder.inverse_transform([0, 1, 2])\n",
    "target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scale Features\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Create MinMaxScaler model & Fit to training data\n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "\n",
    "# Transform training & testing data using X_scaler\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rpmcl\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(max_iter=1000)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.6654587068472249\n",
      "Testing Data Score: 0.6596109839816934\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {classifier.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {classifier.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 predictions: ['CANDIDATE', 'CANDIDATE', 'FALSE POSITIVE', 'FALSE POSITIVE', 'FALSE POSITIVE', 'CONFIRMED', 'CONFIRMED', 'FALSE POSITIVE', 'CANDIDATE', 'FALSE POSITIVE']\n",
      "First 10 real: ['FALSE POSITIVE', 'CANDIDATE', 'FALSE POSITIVE', 'FALSE POSITIVE', 'FALSE POSITIVE', 'CONFIRMED', 'CANDIDATE', 'CANDIDATE', 'CANDIDATE', 'FALSE POSITIVE']\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test)\n",
    "print(f\"First 10 predictions: {predictions[:10].tolist()}\")\n",
    "print(f\"First 10 real: {y_test[:10].tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "     CANDIDATE       0.44      0.23      0.31       411\n",
      "     CONFIRMED       0.64      0.68      0.66       484\n",
      "FALSE POSITIVE       0.72      0.85      0.78       853\n",
      "\n",
      "      accuracy                           0.66      1748\n",
      "     macro avg       0.60      0.59      0.58      1748\n",
      "  weighted avg       0.63      0.66      0.63      1748\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Classification Report\n",
    "from sklearn.metrics import classification_report\n",
    "# predictions = model.predict(X_test)\n",
    "print(classification_report(y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_scaled, y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.8483692542437535\n",
      "Testing Data Score: 0.8443935926773455\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {model.score(X_train_scaled, y_train_encoded)}\")\n",
    "print(f\"Testing Data Score: {model.score(X_test_scaled, y_test_encoded)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 predictions: ['FALSE POSITIVE', 'CANDIDATE', 'FALSE POSITIVE', 'FALSE POSITIVE', 'FALSE POSITIVE', 'CONFIRMED', 'CONFIRMED', 'CANDIDATE', 'CANDIDATE', 'FALSE POSITIVE']\n",
      "First 10 real: ['FALSE POSITIVE', 'CANDIDATE', 'FALSE POSITIVE', 'FALSE POSITIVE', 'FALSE POSITIVE', 'CONFIRMED', 'CANDIDATE', 'CANDIDATE', 'CANDIDATE', 'FALSE POSITIVE']\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test_scaled)\n",
    "print(f\"First 10 predictions: {label_encoder.inverse_transform(predictions[:10]).tolist()}\")\n",
    "print(f\"First 10 real: {label_encoder.inverse_transform(y_test_encoded[:10]).tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "     CANDIDATE       0.70      0.63      0.67       411\n",
      "     CONFIRMED       0.72      0.75      0.73       484\n",
      "FALSE POSITIVE       0.98      1.00      0.99       853\n",
      "\n",
      "      accuracy                           0.84      1748\n",
      "     macro avg       0.80      0.79      0.80      1748\n",
      "  weighted avg       0.84      0.84      0.84      1748\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Classification Report\n",
    "from sklearn.metrics import classification_report\n",
    "# predictions = model.predict(X_test_scaled)\n",
    "print(classification_report(y_test_encoded, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Residual Plot, Add Feature Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Residual Values [Residual = Observed - Predicted]\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# predictions = model.predict(X_test_scaled)\n",
    "plt.scatter(model.predict(X_train_scaled), y_train_encoded - model.predict(X_train_scaled), c=\"blue\", label=\"Training Data\")\n",
    "plt.scatter(model.predict(X_test_scaled), y_test_encoded - model.predict(X_test_scaled), c=\"orange\", label=\"Testing Data\")\n",
    "plt.legend()\n",
    "plt.hlines(y=0, xmin=y_test_encoded.min(), xmax=y_test_encoded.max())\n",
    "plt.title(\"Residual Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1748"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_score = model.predict_proba(X_test_scaled)[:,1]\n",
    "len(y_score)\n",
    "# len(y_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "roc_curve() got an unexpected keyword argument 'average'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-882881221618>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mfalse_positive_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrue_positive_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test_encoded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: roc_curve() got an unexpected keyword argument 'average'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "false_positive_rate, true_positive_rate, threshold = roc_curve(y_test_encoded, y_score, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-fdef914112df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'roc_auc_score for Logistic Regression: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test_encoded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_class\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ovr\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[0;32m    536\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"multi_class must be in ('ovo', 'ovr')\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m         return _multiclass_roc_auc_score(y_true, y_score, labels,\n\u001b[1;32m--> 538\u001b[1;33m                                          multi_class, average, sample_weight)\n\u001b[0m\u001b[0;32m    539\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36m_multiclass_roc_auc_score\u001b[1;34m(y_true, y_score, labels, multi_class, average, sample_weight)\u001b[0m\n\u001b[0;32m    593\u001b[0m     \"\"\"\n\u001b[0;32m    594\u001b[0m     \u001b[1;31m# validation of the input y_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 595\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    596\u001b[0m         raise ValueError(\n\u001b[0;32m    597\u001b[0m             \u001b[1;34m\"Target scores need to be probabilities for multiclass \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m     36\u001b[0m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n\u001b[0;32m     37\u001b[0m          initial=_NoValue, where=True):\n\u001b[1;32m---> 38\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m def _prod(a, axis=None, dtype=None, out=None, keepdims=False,\n",
      "\u001b[1;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "print('roc_auc_score for Logistic Regression: ', roc_auc_score(y_test_encoded, y_score, multi_class=\"ovr\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "multiclass format is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-0661d8d6c508>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_scaled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprobs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mfpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroc_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test_encoded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mroc_auc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[0;32m    912\u001b[0m     \"\"\"\n\u001b[0;32m    913\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[1;32m--> 914\u001b[1;33m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m     \u001b[1;31m# Attempt to drop thresholds corresponding to points in between and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[0;32m    689\u001b[0m     if not (y_type == \"binary\" or\n\u001b[0;32m    690\u001b[0m             (y_type == \"multiclass\" and pos_label is not None)):\n\u001b[1;32m--> 691\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{0} format is not supported\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    692\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    693\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: multiclass format is not supported"
     ]
    }
   ],
   "source": [
    "probs = model.predict_proba(X_test_scaled)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test_encoded, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='GridSearchCV (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "# plt.savefig('Log_ROC')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Tuning (Hyperparameters)\n",
    "\n",
    "Use `GridSearchCV` to tune the model's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['C', 'class_weight', 'dual', 'fit_intercept', 'intercept_scaling', 'l1_ratio', 'max_iter', 'multi_class', 'n_jobs', 'penalty', 'random_state', 'solver', 'tol', 'verbose', 'warm_start'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get list of available parameters\n",
    "model.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the GridSearchCV model\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# # param_grid = {'C': [1, 5, 10], \n",
    "# #               'gamma': [0.0001, 0.001, 0.01]}\n",
    "\n",
    "# param_grid = {'penalty': ['l1', 'l2'],\n",
    "#               'C': np.logspace(-4, 4, 20),\n",
    "#               'solver': ['liblinear']}\n",
    "\n",
    "\n",
    "# grid = GridSearchCV(model, param_grid, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "[CV] END .............C=0.0001, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END .............C=0.0001, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END .............C=0.0001, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END .............C=0.0001, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END .............C=0.0001, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END .............C=0.0001, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END .............C=0.0001, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END .............C=0.0001, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END .............C=0.0001, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END .............C=0.0001, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.00026366508987303583, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.00026366508987303583, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.00026366508987303583, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.00026366508987303583, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.00026366508987303583, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.00026366508987303583, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.00026366508987303583, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.00026366508987303583, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.00026366508987303583, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.00026366508987303583, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.0006951927961775605, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.0006951927961775605, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.0006951927961775605, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.0006951927961775605, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.0006951927961775605, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.0006951927961775605, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.0006951927961775605, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.0006951927961775605, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.0006951927961775605, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.0006951927961775605, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.0018329807108324356, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.0018329807108324356, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.0018329807108324356, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.0018329807108324356, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.0018329807108324356, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.0018329807108324356, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.0018329807108324356, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.0018329807108324356, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.0018329807108324356, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.0018329807108324356, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.004832930238571752, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.004832930238571752, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.004832930238571752, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.004832930238571752, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.004832930238571752, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.004832930238571752, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.004832930238571752, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.004832930238571752, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.004832930238571752, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.004832930238571752, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.012742749857031334, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.012742749857031334, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.012742749857031334, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.012742749857031334, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.012742749857031334, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.012742749857031334, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.012742749857031334, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.012742749857031334, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.012742749857031334, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.012742749857031334, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.03359818286283781, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.03359818286283781, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.03359818286283781, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.03359818286283781, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.03359818286283781, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.03359818286283781, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.03359818286283781, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.03359818286283781, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.03359818286283781, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.03359818286283781, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.08858667904100823, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.08858667904100823, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.08858667904100823, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.08858667904100823, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.08858667904100823, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.08858667904100823, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.08858667904100823, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.08858667904100823, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.08858667904100823, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.08858667904100823, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.23357214690901212, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.23357214690901212, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.23357214690901212, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.23357214690901212, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.23357214690901212, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.23357214690901212, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.23357214690901212, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.23357214690901212, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.23357214690901212, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.23357214690901212, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END ..C=0.615848211066026, penalty=l1, solver=liblinear; total time=   0.1s\n",
      "[CV] END ..C=0.615848211066026, penalty=l1, solver=liblinear; total time=   0.1s\n",
      "[CV] END ..C=0.615848211066026, penalty=l1, solver=liblinear; total time=   0.1s\n",
      "[CV] END ..C=0.615848211066026, penalty=l1, solver=liblinear; total time=   0.1s\n",
      "[CV] END ..C=0.615848211066026, penalty=l1, solver=liblinear; total time=   0.1s\n",
      "[CV] END ..C=0.615848211066026, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END ..C=0.615848211066026, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END ..C=0.615848211066026, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END ..C=0.615848211066026, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END ..C=0.615848211066026, penalty=l2, solver=liblinear; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..C=1.623776739188721, penalty=l1, solver=liblinear; total time=   0.5s\n",
      "[CV] END ..C=1.623776739188721, penalty=l1, solver=liblinear; total time=   0.4s\n",
      "[CV] END ..C=1.623776739188721, penalty=l1, solver=liblinear; total time=   0.4s\n",
      "[CV] END ..C=1.623776739188721, penalty=l1, solver=liblinear; total time=   0.4s\n",
      "[CV] END ..C=1.623776739188721, penalty=l1, solver=liblinear; total time=   0.7s\n",
      "[CV] END ..C=1.623776739188721, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END ..C=1.623776739188721, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END ..C=1.623776739188721, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END ..C=1.623776739188721, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END ..C=1.623776739188721, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END ..C=4.281332398719396, penalty=l1, solver=liblinear; total time=   2.2s\n",
      "[CV] END ..C=4.281332398719396, penalty=l1, solver=liblinear; total time=   1.4s\n",
      "[CV] END ..C=4.281332398719396, penalty=l1, solver=liblinear; total time=   1.0s\n",
      "[CV] END ..C=4.281332398719396, penalty=l1, solver=liblinear; total time=   0.9s\n",
      "[CV] END ..C=4.281332398719396, penalty=l1, solver=liblinear; total time=   1.8s\n",
      "[CV] END ..C=4.281332398719396, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END ..C=4.281332398719396, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END ..C=4.281332398719396, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END ..C=4.281332398719396, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END ..C=4.281332398719396, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END .C=11.288378916846883, penalty=l1, solver=liblinear; total time=   4.1s\n",
      "[CV] END .C=11.288378916846883, penalty=l1, solver=liblinear; total time=   3.0s\n",
      "[CV] END .C=11.288378916846883, penalty=l1, solver=liblinear; total time=   1.6s\n",
      "[CV] END .C=11.288378916846883, penalty=l1, solver=liblinear; total time=   2.4s\n",
      "[CV] END .C=11.288378916846883, penalty=l1, solver=liblinear; total time=   2.6s\n",
      "[CV] END .C=11.288378916846883, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END .C=11.288378916846883, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END .C=11.288378916846883, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END .C=11.288378916846883, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END .C=11.288378916846883, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END .C=29.763514416313132, penalty=l1, solver=liblinear; total time=   5.5s\n",
      "[CV] END .C=29.763514416313132, penalty=l1, solver=liblinear; total time=   5.2s\n",
      "[CV] END .C=29.763514416313132, penalty=l1, solver=liblinear; total time=   2.6s\n",
      "[CV] END .C=29.763514416313132, penalty=l1, solver=liblinear; total time=   5.1s\n",
      "[CV] END .C=29.763514416313132, penalty=l1, solver=liblinear; total time=   5.4s\n",
      "[CV] END .C=29.763514416313132, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END .C=29.763514416313132, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END .C=29.763514416313132, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END .C=29.763514416313132, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END .C=29.763514416313132, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END ..C=78.47599703514607, penalty=l1, solver=liblinear; total time=  11.1s\n",
      "[CV] END ..C=78.47599703514607, penalty=l1, solver=liblinear; total time=   6.1s\n",
      "[CV] END ..C=78.47599703514607, penalty=l1, solver=liblinear; total time=   3.5s\n",
      "[CV] END ..C=78.47599703514607, penalty=l1, solver=liblinear; total time=  13.3s\n",
      "[CV] END ..C=78.47599703514607, penalty=l1, solver=liblinear; total time=  17.4s\n",
      "[CV] END ..C=78.47599703514607, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END ..C=78.47599703514607, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END ..C=78.47599703514607, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END ..C=78.47599703514607, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END ..C=78.47599703514607, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END ...C=206.913808111479, penalty=l1, solver=liblinear; total time=  17.8s\n",
      "[CV] END ...C=206.913808111479, penalty=l1, solver=liblinear; total time=   9.8s\n",
      "[CV] END ...C=206.913808111479, penalty=l1, solver=liblinear; total time=   5.7s\n",
      "[CV] END ...C=206.913808111479, penalty=l1, solver=liblinear; total time=  15.5s\n",
      "[CV] END ...C=206.913808111479, penalty=l1, solver=liblinear; total time=  21.6s\n",
      "[CV] END ...C=206.913808111479, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END ...C=206.913808111479, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END ...C=206.913808111479, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END ...C=206.913808111479, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END ...C=206.913808111479, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END ..C=545.5594781168514, penalty=l1, solver=liblinear; total time=  18.2s\n",
      "[CV] END ..C=545.5594781168514, penalty=l1, solver=liblinear; total time=  11.2s\n",
      "[CV] END ..C=545.5594781168514, penalty=l1, solver=liblinear; total time=   3.4s\n",
      "[CV] END ..C=545.5594781168514, penalty=l1, solver=liblinear; total time=  14.4s\n",
      "[CV] END ..C=545.5594781168514, penalty=l1, solver=liblinear; total time=  18.4s\n",
      "[CV] END ..C=545.5594781168514, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END ..C=545.5594781168514, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END ..C=545.5594781168514, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..C=545.5594781168514, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..C=545.5594781168514, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ...C=1438.44988828766, penalty=l1, solver=liblinear; total time=  18.6s\n",
      "[CV] END ...C=1438.44988828766, penalty=l1, solver=liblinear; total time=  11.3s\n",
      "[CV] END ...C=1438.44988828766, penalty=l1, solver=liblinear; total time=   3.9s\n",
      "[CV] END ...C=1438.44988828766, penalty=l1, solver=liblinear; total time=  14.2s\n",
      "[CV] END ...C=1438.44988828766, penalty=l1, solver=liblinear; total time=  15.1s\n",
      "[CV] END ...C=1438.44988828766, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ...C=1438.44988828766, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ...C=1438.44988828766, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ...C=1438.44988828766, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ...C=1438.44988828766, penalty=l2, solver=liblinear; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rpmcl\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..C=3792.690190732246, penalty=l1, solver=liblinear; total time= 2.9min\n",
      "[CV] END ..C=3792.690190732246, penalty=l1, solver=liblinear; total time=  13.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rpmcl\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..C=3792.690190732246, penalty=l1, solver=liblinear; total time= 2.9min\n",
      "[CV] END ..C=3792.690190732246, penalty=l1, solver=liblinear; total time=  14.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rpmcl\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..C=3792.690190732246, penalty=l1, solver=liblinear; total time= 3.0min\n",
      "[CV] END ..C=3792.690190732246, penalty=l2, solver=liblinear; total time=   0.3s\n",
      "[CV] END ..C=3792.690190732246, penalty=l2, solver=liblinear; total time=   0.3s\n",
      "[CV] END ..C=3792.690190732246, penalty=l2, solver=liblinear; total time=   0.3s\n",
      "[CV] END ..C=3792.690190732246, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..C=3792.690190732246, penalty=l2, solver=liblinear; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rpmcl\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............C=10000.0, penalty=l1, solver=liblinear; total time= 3.0min\n",
      "[CV] END ............C=10000.0, penalty=l1, solver=liblinear; total time=  12.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rpmcl\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............C=10000.0, penalty=l1, solver=liblinear; total time= 2.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rpmcl\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............C=10000.0, penalty=l1, solver=liblinear; total time= 2.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rpmcl\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............C=10000.0, penalty=l1, solver=liblinear; total time= 2.9min\n",
      "[CV] END ............C=10000.0, penalty=l2, solver=liblinear; total time=   0.4s\n",
      "[CV] END ............C=10000.0, penalty=l2, solver=liblinear; total time=   0.3s\n",
      "[CV] END ............C=10000.0, penalty=l2, solver=liblinear; total time=   0.4s\n",
      "[CV] END ............C=10000.0, penalty=l2, solver=liblinear; total time=   0.3s\n",
      "[CV] END ............C=10000.0, penalty=l2, solver=liblinear; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rpmcl\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(max_iter=1000),\n",
       "             param_grid={'C': array([1.00000000e-04, 2.63665090e-04, 6.95192796e-04, 1.83298071e-03,\n",
       "       4.83293024e-03, 1.27427499e-02, 3.35981829e-02, 8.85866790e-02,\n",
       "       2.33572147e-01, 6.15848211e-01, 1.62377674e+00, 4.28133240e+00,\n",
       "       1.12883789e+01, 2.97635144e+01, 7.84759970e+01, 2.06913808e+02,\n",
       "       5.45559478e+02, 1.43844989e+03, 3.79269019e+03, 1.00000000e+04]),\n",
       "                         'penalty': ['l1', 'l2'], 'solver': ['liblinear']},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model with GridSearch\n",
    "grid.fit(X_train_scaled, y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10000.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.8851774499887206\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save your model by updating \"your_name\" with your name\n",
    "# and \"your_model\" with your model variable\n",
    "# be sure to turn this in to BCS\n",
    "# if joblib fails to import, try running the command to install in terminal/git-bash\n",
    "import joblib\n",
    "filename = 'your_name.sav'\n",
    "# joblib.dump(your_model, filename)\n",
    "joblib.dump(model, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "dev"
  },
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
